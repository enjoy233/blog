<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Dynamic scheduling crawler for FeedPusher | TaoAlpha's Blog</title><meta name="description" content="how to crawl subscriptions more intelligiently"><meta name="viewport" content="width=device-width, initial-scale=1"><!-- open graph part--><meta property="og:title" content="Dynamic scheduling crawler for FeedPusher | TaoAlpha's Blog"><meta property="og:description" content="how to crawl subscriptions more intelligiently"><meta property="og:url" content="undefined"><meta property="og:image" content="http://taoalpha.github.io/images/newblog.jpg"><meta property="og:type" content="website"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.0.0/animate.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hint.css/2.6.0/hint.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.1/css/all.min.css"><link rel="short icon" href="/blog/favicon.png"><link rel="stylesheet" href="/blog/css/default.css"><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/blog/atom.xml" title="TaoAlpha's Blog" type="application/atom+xml">
<link rel="alternate" href="/blog/rss2.xml" title="TaoAlpha's Blog" type="application/rss+xml">
</head><body class="post"><aside class="home-menu"><nav class="home-icon-con upside"><a href="/blog/" class="home-menu-icon brand">涛</a><a href="/blog/timeline" class="home-menu-icon"><i class="fas fa-map-marker-alt"></i></a><a aria-label="Click to take you to the search box." class="home-menu-icon search-trigger hint--right"><i class="fas fa-search"></i></a><a href="javascript:;" title="Contact Me" class="home-menu-icon follow">+</a><div class="home-contact hidden"><a href="https://facebook.com/zzgary/" target="something"><img src="https://cdn1.iconfinder.com/data/icons/social-shade-rounded-rects/512/facebook-32.png" alt="facebook"></a><a href="https://github.com/taoalpha/" target="something"><img src="https://cdn1.iconfinder.com/data/icons/social-shade-rounded-rects/512/github-32.png" alt="github"></a><a href="https://taoalpha.github.io" target="something"><img src="https://cdn3.iconfinder.com/data/icons/colore-sociale/32/mewally_32x32.png" alt="portfolio"></a><a href="https://douban.com/people/129154019" target="something"><img src="https://img3.doubanio.com/favicon.ico" alt="douban"></a></div></nav><nav class="home-icon-con downside"><a href="/blog/rss2.xml" class="home-menu-icon rss"><i class="fas fa-rss"></i></a><a href="/blog/about/" class="home-menu-icon"><i class="fas fa-smile"></i></a><span id="dark-mode" class="home-menu-icon hidden"><i class="fas fa-adjust"></i></span></nav></aside><div class="stars"></div><div class="twinkling"></div><div id="progress-bar" class="hidden"><span class="bg"></span></div><article id="content"><div class="main"><section class="entry"><h1 class="entry-title">Dynamic scheduling crawler for FeedPusher</h1><div class="meta-top"><a href="https://taoalpha.github.io"><div style="display:inline-block;" class="avatar"><img src="https://avatars3.githubusercontent.com/u/4335753?v=3&amp;s=40" alt="100"></div><span>TaoAlpha</span></a><span>2016-01-12</span><span class="wordage">4305 words</span><span class="readspeed">13 minutes to read</span></div><div class="entry-content"><p>As I promised, I have been working on refactoring the feedpusher with pure JS/nodeJS from last week. Now I have set up the basic database struture and spider which has already been running for one week with 80 sites and 8k feeds stored into my mongodb on raspberry pi.</p>
<p>Today, I jsut set up a new process to crawl the updates which I called dynamic scheduling which means now the spider can decide whether this site needs to be recrawled this time or not by itself. Why? Most important reason is that as the number of sites goes bigger, the time it crawles all sites is longer, and also crawl every site everytime is not a good way.</p>
<p>Now I will explain how I do that with nodeJS.</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>Our purpose is let the spider decide when to crawl a specific website/rss link, or in another word, everytime the spider runs, it needs to decide which website should be recrawled this time.</p>
<h3 id="What-data-I-have"><a href="#What-data-I-have" class="headerlink" title="What data I have"></a>What data I have</h3><p>Now I have and I can store some data into my database that may be good for this purpose, but we want to use as few as possible, so I decide to use these two attributes:</p>
<ul>
<li>lastCrawled: time I last crawled this website;</li>
<li>updateDuration: the duration between two continuous crawl of this site;</li>
</ul>
<h3 id="Dynamic-Scheduling"><a href="#Dynamic-Scheduling" class="headerlink" title="Dynamic Scheduling"></a>Dynamic Scheduling</h3><p>The lastCrawled is pretty simple and we don’t have a lot things can do with it. But the updateDuration is the core of the dynamic scheduling, since we can increase it and tell the spider that this site needs a longer duration before next crawling and vice versa.</p>
<p>So the basic idea is:</p>
<p><strong>The larger the updateDuration is, the longer the website get recrawled.</strong></p>
<h3 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h3><ul>
<li>When to crawl: if current time minus the time lastCrawled is longer than the updateDuration, then the website needs to be recrawled;</li>
<li>Motivate: if this round of crawling got any updates(new feeds) of this website, then we decrease the updateDuration of this website which is like motivating this website because of the updates;</li>
<li>Penalize: if this round of crawling got no updates(new feeds) of this website, then we increase the updateDuration of this website which is like penalizing this website because of the later update than expected;</li>
</ul>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>Based on these simple rules, the updateDuration of one site would be dynamic changing and will reflect the frequency of a website updates in some level.</p>
<h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The coding part is pretty stright forward, but since the spider need get a lot of data from the mongodb, so you might need a lot promises to make sure the order of different processes is under your control.</p>
<p>I will put the Pseudocode here, if you are interested in the real code, you can check my feedpusher code refactoring repo :)</p>
<h3 id="Pseudocode"><a href="#Pseudocode" class="headerlink" title="Pseudocode"></a>Pseudocode</h3><p>This is not a real pseudocode… but I believe you can bare with that :)</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// feed is the object of my core class I used for this spider</span></span><br><span class="line"></span><br><span class="line">feed.db.open(<span class="function">(<span class="params">err, db</span>) =&gt;</span>&#123;</span><br><span class="line">  <span class="comment">// connect with database</span></span><br><span class="line">  <span class="keyword">var</span> allSites = [] <span class="comment">// store all sites we crawled this time in order to update the lastCrawled and updateDuration later</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// find all sites from the database</span></span><br><span class="line">  feed.findAllSites().then(<span class="function">(<span class="params">data</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> curTime = moment()</span><br><span class="line">    <span class="comment">// Need use promise to make sure all finished before you update the lastCrawled and updateDuration</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.all(data.filter( <span class="function">(<span class="params">v</span>) =&gt;</span> &#123;</span><br><span class="line">      <span class="comment">// filter all sites that the time from lastCrawled has passed the updateDuration</span></span><br><span class="line">      <span class="keyword">return</span> (((curTime - moment(v.lastCrawled)) / <span class="number">3600</span> / <span class="number">1000</span>) &gt; v.updateDuration)</span><br><span class="line">    &#125;)</span><br><span class="line">    .map( <span class="function">(<span class="params">v</span>) =&gt;</span>&#123;</span><br><span class="line">      <span class="comment">// crawl and store each feedUrl which is the link of the rss</span></span><br><span class="line">      allSites.push(v.feedUrl)</span><br><span class="line">      <span class="keyword">return</span> feed.crawler(v.feedUrl)</span><br><span class="line">    &#125;) )</span><br><span class="line">  &#125;)</span><br><span class="line">  .then( <span class="function"><span class="params">()</span>=&gt;</span>&#123;</span><br><span class="line">    <span class="comment">// update the lastFCrawled for all sites</span></span><br><span class="line">    <span class="keyword">return</span> feed.updateCrawled(allSites)</span><br><span class="line">  &#125;,(reason)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"Broken at crawler"</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(reason)</span><br><span class="line">    db.close()</span><br><span class="line">  &#125;)</span><br><span class="line">  .then( <span class="function"><span class="params">()</span>=&gt;</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(feed.stats)</span><br><span class="line">    feed.updateDuration(allSites).then( <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="comment">// Now update the updateDuration for all sites</span></span><br><span class="line">      db.close()</span><br><span class="line">    &#125;,(reason)=&gt;&#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">"Broken at updatedDuration"</span>)</span><br><span class="line">      <span class="built_in">console</span>.log(reason)</span><br><span class="line">      db.close()</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;,(reason)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"Broken at updatedCrawled"</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(reason)</span><br><span class="line">    db.close()</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>Yup! currently it works pretty good! :)</p>
</div><div class="post-info"><span class="category"><i class="fas fa-briefcase"></i><a href="/blog/categories/tech">tech</a></span><span class="tags"><i class="fas fa-tags"></i><a href="/blog/tags/js">js</a></span></div></section><div class="widgets"><aside id="menuIndex" class="sidenav hidden"></aside><aside class="sidenav"><input type="text" placeholder="Enter to search" class="st-default-search-input searchbox"></aside><div class="related-posts sidenav"><h2>Related Posts:</h2><ul class="article-list"><li><a href="/blog/2016/08/27/tech-type-check-in-js/">Type check in JS</a></li><li><a href="/blog/2016/08/13/tech-deep-copy-in-javascript/">Deep copy in javascript</a></li><li><a href="/blog/2016/06/17/tech-javascript-module-system/">Javascript Module Standard</a></li><li><a href="/blog/2016/04/29/tech-defineproperty-in-javascript/">defineProperty in JavaScript</a></li><li><a href="/blog/2016/04/28/tech-symbol-and-iterate-object-in-es6/">Symbol and Iterate Object in ES6</a></li></ul></div><aside class="sidenav"><div class="recent-posts"><h2>Recent Posts:</h2><ul class="article-list"><li><a href="/blog/2020/07/06/thoughts-recommendation-to-new-grads-on-job-choices/">给新计算机毕业生在工作选择上的一些建议</a></li><li><a href="/blog/2020/07/04/travel-working-holiday-visa-3/">打工度假 (三)</a></li><li><a href="/blog/2020/07/02/travel-working-holiday-visa-2/">打工度假 (二)</a></li><li><a href="/blog/2020/07/02/tech-what-i-have-done-to-restart-this-blog/">我都做了哪些来复活本博客的</a></li><li><a href="/blog/2020/07/01/travel-working-holiday-visa/">打工度假 (一)</a></li></ul></div></aside></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.css"><script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.js"></script><div class="comments"><script>const gitment = new Gitment({
  id: new Date('Tue Jan 12 2016 07:00:00 GMT-0500').toISOString(),
  owner: 'taoalpha',
  repo: 'blog',
  oauth: {
    client_id: '875872ffb3955d0ffe20',
    client_secret: '46040668c536860a9e2e9a8508c513309e3840b5',
  },
});
gitment.render(document.querySelector('.comments'));
</script></div></article><div class="notification fail hidden"></div><!-- jquery--><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-46725017-2",'auto');ga('send','pageview');</script><script>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
_st('install','CUMLELEvkSRAFuVehSCm','2.0.0');</script><!-- main functions--><script src="/blog/js/functions.js"></script><script src="/blog/js/default.js"></script><script src="/blog/js/post.js"></script></body></html>